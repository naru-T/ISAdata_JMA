---
title: Sub-Pixel Classification of MODIS EVI for Annual Mappings of Impervious Surface
  Areas
author: Narumasa Tsutsumida ^1\*,2†^, Alexis Comber ^2,3†^, Kirsten Barrett ^2^, Izuru
  Saizen ^1^ and Ernan Rustiadi ^4^
csl: mdpi.csl
output:
  pdf_document:
    fig_caption: yes
    latex_engine: xelatex
  html_notebook: null
  html_document: default
geometry: margin=3cm
bibliography: 2016 Remote Sensing.bib
---

^1^ Graduate School of Global Environmental Studies, Kyoto University, Kyoto 606-8501, Japan; saizen@kais.kyoto-u.ac.jp

^2^ Department of Geography, University of Leicester, Leicester LE1 7RH, UK; kirsten.barrett@leicester.ac.uk

^3^ School of Geography, University of Leeds, Leeds, LS2 9JT, UK; a.comber@leeds.ac.uk 

^4^ Faculty of Agriculture, Bogor Agricultural University, Bogor 16680, Indonesia; ernan@indo.net.id

^\*^ Correspondence: naru@kais.kyoto-u.ac.jp; Tel.: +81-75-753-6368

^†^ These authors contributed equally to this work.


[NOTE] *The output values are slightly different from published paper due to the failure of setting set.seed() function.*  
  
  



```{r pacakges, message=FALSE, warning=FALSE, echo = FALSE}
# set the working directory
#setwd("/Volumes/SHARE/Dropbox/CompleteTask/201602RandomForest_paper/Analysis")
setwd(".")

set.seed(300)

#load library
  require(raster)
  require(randomForest)
  require(rpart)
  require(rgdal)
  require(zoo)
  require(signal)
  require(maptools)
  require(RColorBrewer)
  require(reshape2)
  require(ggplot2)
  require(rasterVis)
  require(shapefiles)
  require(rfUtilities)
  require(gridExtra)
  require(hexbin) 
  require(knitr)
  
options(scipen=10)

knitr::opts_chunk$set(eval = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)
knitr::opts_chunk$set(message = FALSE)

```


```{r functions, include=FALSE}
# A function for captioning and referencing figures
fig <- local({
    i <- 0
    ref <- list()
    list(
        cap=function(refName, text) {
            i <<- i + 1
            ref[[refName]] <<- i
            paste( text, sep="")
        },
        ref=function(refName) {
            ref[[refName]]
        })
})

###### define functions which this analysis used.
##0.1 Our functions to be used---------------------
  confusion_matrix <- function(class, pred){
    #2 classes  
    tab <- table(class,pred)
    tab <- cbind(tab, rowSums(tab))
    tab <- rbind(tab, colSums(tab))
    colnames(tab)[3]<-"Total";  rownames(tab)[3]<-"Total"
    tab <- t(tab) #transpose the table
    # Users accuracy
    tmp <- vector(mode = "numeric", length = 3) 
    for (i in 1:2) {
      tmp[i] <- tab[i,i] / tab[i,3]
    }
    tab <- cbind(tab, zapsmall(tmp, 3))
    colnames(tab)[4] <- "User's"
    # Producers accuracy
    tmp <- vector(mode = "numeric", length = 4) 
    for (i in 1:2) {
      tmp[i] <- tab[i,i] / tab[3,i]
    }
    tab <- rbind(tab, zapsmall(tmp, 3))
    rownames(tab)[4] <- "Producer's"
    tab[4,4] <- sum(diag(table(class,pred)))/sum(table(class,pred))
    return(tab)
  }
  
  oob_matrix <- function(rf.ans){
    tab <- rf.ans$confusion
    tab[,3] <- tab[,1] + tab[,2]
    tab <- rbind(tab, c((tab[1, ] + tab[2, ])))
    colnames(tab)[3] <- "total"
    rownames(tab)[3] <- "total"
    tab <- cbind(tab, round(c((tab[1, 1] / tab[1, 3]), (tab[2, 2] / tab[2, 3]) , NA), 3))
    tab <- rbind(tab, round(c((tab[1, 1] / tab[3, 1]), (tab[2, 2] / tab[3, 2]) , NA, NA),3))
    colnames(tab)[4] <- "User"
    rownames(tab)[4] <- "Producer"
    return(tab)
  }
  
  annual_confusion_matrix <- function(point, stk, per){
    tab.list=list()
    valid.length <- c()
    for(j in 2001:2013){ 
      n=j-2000
      eval(parse(text=paste("pt=subset(point,Year=='",j,"')",sep="")))
      sortlist=order(pt$ID)
      pt=pt[sortlist,]
      
      # at each vilaidation examine image and put answer into rasValue 
      # predict value into point
      eval(parse(text=paste("pred.data=extract(stk$Y",j,",pt)",sep="")))
      
      if (per=="25"){
        ref.data=pt@data$Imp25p
      } else if (per=="50"){
        ref.data=pt@data$Imp50p
      } else if (per=="75"){
        ref.data=pt@data$Imp75p
      }
      
      #Accuracy assessment by each year
      #predection data
      pred.data=sub(1,"Impervious",pred.data)
      pred.data=sub(2,"Others",pred.data)
      
      #data length
      valid.length=cbind(valid.length,length(ref.data))
      valid.length[n]=length(ref.data)
      #calculate user's/producer's matrix
      tab <- confusion_matrix(ref.data,pred.data)
      tab.list=append(tab.list,list(tab)) 
      
    }
    return(tab.list)
  }
  
  annual_confusion_matrix_prop <- function(point, stk){
    rsqP=list()
    rmseP=list()
    valid.length <- c()
    for(j in 2001:2013){ 
      n=j-2000
      eval(parse(text=paste("pt=subset(point,Year=='",j,"')",sep="")))
      sortlist=order(pt$ID)
      pt=pt[sortlist,] 
      #add predict value into point
      eval(parse(text=paste("rasValue=extract(stk$Y",j,",pt)",sep="")))
      pt@data$PredictP=rasValue
      #Accuracy assessment by each year
      #predection data
      pred.data=pt@data$PredictP
      #validation data
      ref.data=pt@data$Impervious
      #data length
      valid.length=cbind(valid.length,length(ref.data))
      valid.length[n]=length(ref.data)
      #calculate user's/producer's matrix
      #cor=cor(ref.data,pred.data)
      rsq <- 1 - sum((ref.data -pred.data)^2)/sum((ref.data -mean(ref.data))^2)
      #rmse=sqrt(mean (ref.data-pred.data)^2)
      rmse <- sqrt( mean( (ref.data - pred.data)^2 , na.rm = TRUE ) )
      rsqP=append(rsqP,list(rsq)) 
      rmseP=append(rmseP,list(rmse)) 
    }
    res=as.data.frame(cbind(rsqP,rmseP))
    names(res)=c("rsqP","rmseP")
    return(res)
  }
  
  
  global_confusion_matrix_prop <- function(point, stk){
    tmp.pred <- c()
    tmp.ref <- c()
    valid.length <- c()
    for(j in 2001:2013){ 
      n=j-2000
      eval(parse(text=paste("pt=subset(point,Year=='",j,"')",sep="")))
      sortlist=order(pt$ID)
      pt=pt[sortlist,] 
      #add predict value into point
      eval(parse(text=paste("rasValue=extract(stk$Y",j,",pt)",sep="")))
      pt@data$PredictP=rasValue
      #Accuracy assessment by each year
      #predection data
      pred.data=pt@data$PredictP
      #validation data
      ref.data=pt@data$Impervious
      #data length
      valid.length=cbind(valid.length,length(ref.data))
      valid.length[n]=length(ref.data)
      tmp.pred <- append(tmp.pred, pred.data) 
      tmp.ref <- append(tmp.ref, ref.data) 
    }
    #calculate user's/producer's matrix
    cor=cor(tmp.pred,tmp.ref)
    #rmse=sqrt(mean (ref.data-pred.data)^2)
    rmse <- sqrt( mean( (tmp.pred - tmp.ref)^2 , na.rm = TRUE ) )
    res.df <- data.frame(tmp.pred,tmp.ref)
    names(res.df) <- c("pred", "ref")
    res <- list(res.df, cor, rmse)
    return(res)
  }
  
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Abstract

  Regular monitoring of expanding impervious surfaces areas (ISAs) in urban areas is highly desirable. MODIS data can meet this demand in terms of frequent observations but are lacking in spatial detail, leading to the mixed land cover problem when per-pixel classifications are applied. To overcome this issue, this research develops and applies a spatio-temporal sub-pixel model to estimate ISAs on an annual basis during 2001–2013 in the Jakarta Metropolitan Area, Indonesia. A Random Forest (RF) regression inferred the ISA proportion from annual 23 values of MODIS MOD13Q1 EVI and reference data in which such proportion was visually allocated from very high-resolution images in Google Earth over time at randomly selected locations. Annual maps of ISA proportion were generated and showed an average increase of 30.65 km^2^/year over 13 years. For comparison, a series of RF per-pixel classifications were also developed from the same reference data using a Boolean class constructed from different thresholds of ISA proportion. Results from per-pixel models varied when such thresholds change, suggesting difficulty of estimation of actual ISAs. This research demonstrated the advantages of spatio-temporal sub-pixel analysis for annual ISAs mapping and addresses the problem associated with definitions of thresholds in per-pixel approaches.

# Keywords
  impervious surface area; urban expansion; MODIS; random forest

# 1. Introduction

  Rates of urbanization have been increasing and are associated with increasing shifts of populations to cities. The extent of the urban area has increased at twice the rate of population growth in developing countries [@Angel2011e]. Urban expansion can be seen with large increase in areas covered with artificial impervious surfaces such as paved roads, parking lots, buildings and rooftops [@Weng2012a; @Sexton2013k]. Increases in impervious surface area (ISA) are associated with transitions from natural and agricultural land and have been found to have significant impacts on local environmental systems. For example, ISA prevents surface water penetration which affects local atmospheric, water and carbon cycles [@Arnold1996], and its expansion contributes to the degradation of biodiversity across local, regional, and global scales [@Alberti2005a; @Mcdonald2008a; @Rojas2013f]. Understanding the spatial and temporal characteristics of ISA expansion can inform strategies for sustainable urban development [@Yang2003b; @Schneider2009b] and regular updates on the spatial distribution of ISAs in urban areas supports urban planning and land use policy [@Yang2003b].  

  Remote sensing data offer the opportunity to provide synoptic monitoring of urban ISAs but data selection frequently involves trade-offs between spatial (and thematic) detail, coverage and repeat frequencies. MODerate resolution Imaging Spectroradiometer (MODIS) data have been used to infer ISA extent and distribution [@Knight2011; @Tsutsumida2013h; @Lunetta2006f] as they support frequent repeat surveys and land surface monitoring. Despite moderate spatial resolution, the high temporal frequency of MODIS has been used to monitor land cover [ @Tsutsumida2013h; @Lunetta2006f; @Clark2012c; @Clark2010e; @Sanchez-Cuervo2012d; @Alvarez-berrios2013c]. However, one of the critical issues using data at medium and coarse spatial resolutions is the mixed pixel problem [@Fisher1997; @Foody1996]. Pixels will typically contain a mix of land covers and the propensity for this is greater with medium and coarse spatial resolution data [@Weng2012a]. Therefore, the way that any land cover class is defined and how classes are allocated are important considerations in traditional per-pixel analyses. In Boolean analyses, a threshold of land cover proportion is applied to generate crisp binary classifications: a pixel with a membership greater than the threshold level is defined as, for example, Class 1, and remainder as Class 2 [@Arnot2004a]. As the nature of such data changes according to the threshold, it is important to determine optimal thresholds for classifications but this is rarely done. Instead thresholds are typically pre-defined without any optimization strategy. To avoid with this issue, sub-pixel classification has been proposed [@Shao2011; @Colditz2012; @Foody2002g; @Li2014]. This approach seeks to identify the areal proportion of classes in each pixel [@Li2014; @Xu2005]. This has not yet been fully applied to a multi-temporal analysis of land cover dynamics. This research applies a spatio-temporal sub-pixel classification approach for the estimation of the ISAs in an annual basis and addresses its advances to compare results from per-pixel classification using a series of different thresholds of crisp classification.  
  
  Sub-pixel classification have been applied using approaches including fuzzy classification [@Zhang2001a; @Zhang1998a], spectral mixture analysis [@Yang2014; @Lu2011; @Wu2003; @Yuan2007] and machine learning algorithms [@Yang2003b; @Shao2011; @Xu2005 ; @Deng2013 ; @Rogan2008a ]. Fuzzy classification explicitly acknowledges uncertainties regarding class membership and allows a degree of membership to each possible thematic class [@Foody2002g ; @Strahler2006b]. Consequently each pixel can have partial memberships to multiple classes [@Zhang1998a ]. However, ambiguous membership definitions may result in a failure to estimate class area proportions appropriately [@Arnot2004a ; @Chen2010 ]. Spectral mixture analysis assumes that the mixed spectrum is representative of land covers in a pixel and that the proportions of spectral component reflect the proportions of land covers in the pixel [@Lu2011,　@Lu2003; @Adams1995]. Despite being a popular image processing technique, spectral mixture analysis is often not suitable for applying to coarse-resolution imagery within heterogeneous urban environments due to the difficulty of deriving pure endmembers in the training data [@Weng2012a; @Deng2013]. Machine learning algorithms have been shown to be reliable and efficient techniques for processing large data volumes and both per-pixel and sub-pixel analyses can be successfully implemented via regression or classification trees and associated ensemble techniques such as Random Forest (RF) [@Yang2003b; @Clark2012c ; @Clark2010e; @Xu2005; @Walton2008b] and support vector machines [@Walton2008b; @Esch2009]. Some studies have shown machine learning algorithms to yield better results than spectral mixture analysis for estimating proportional ISA [@Deng2013; @Yuan2008c]; Yuan *et al.* (2008) found that regression trees produced better results than spectral mixture analysis and Deng and Wu (2013) showed RF to better than spectral mixture analysis when sufficient random sampled reference data are available.  
  
  A number of studies have used RF approaches to classify land cover in per-pixel [@Gislason2006a; @Pal2005a; @Rodriguez-Galiano2012; @Wang2015b ; @Balzter2015], sub-pixel [@Deng2013 ; @Walton2008b ; @Reschke2014a], and spatio-temporal per-pixel approaches [@Clark2012c @Clark2010e ; @Sanchez-Cuervo2012d ]. In particular, Clark *et al.* (2010) applied a per-pixel RF classifier to MODIS time series to produce annual land cover mappings. They determined land covers from annual phenological metrics derived from Enhanced Vegetation Index (EVI) data and topographical metrics. Clark *et al.* (2012) extended this analysis using mean, standard deviation, minimum, maximum and range for EVI, and red, near infrared and mid-infrared reflectance values. These approaches focused combinations of variables so that the outputs yielded the maximum accuracy measures, however it is difficult to interpret the meaning of the classification in relation to the combination of different types of input variables. In this context, the selection of a simple and tractable set of variables would support wider multi-temporal analyses of land cover.  
  
  In summary, much research has suggested methods for quantifying annual land cover from multi-temporal data. However, sub-pixel approaches have not yet been applied in multi-temporal analyses to examine ISA despite their frequent use. In addition, pursuit of the highest accuracy of outputs may result in model opaquely parameterised by input variables and whose selection is complex. Therefore, this research produces annual ISA maps along with highlighting: (1) the application of a spatio-temporal sub-pixel classification; (2) the use of tractable input variables into the model; and (3) inconsistent results from per-pixel analyses when using different thresholds of land cover definitions. Using the Jakarta Metropolitan Area (JMA) as a case study, this research develops a sub-pixel classification of ISAs using MODIS EVI data using a RF regression during the period 2001–2013. It is assumed that it would be more insightful to use all of temporal values rather than aggregating them, especially when interpreting the classification of annual patterns of EVI. Thus, all 23 yearly values of the 16-days composite MODIS MOD09Q1 EVI are explored as input variables.  
  
  These time-series values are regarded as a proxy of annual phenological pattern of EVI and were used to estimate ISAs with spatially and temporally distributed reference data collected from available very high resolution (VHR) images in Google Earth (GE). Reference data were randomly selected at 1000 locations in the study area and the proportions of ISA were recorded for each over 13 years. This sub-pixel RF model produced 13 annual maps and inferred the proportion of ISA. Standard per-pixel analyses using a series of crisp reference data produced from different thresholds of ISA proportion were also generated to provide a comparison to the sub-pixel approach. These models demonstrated how the selection of such thresholds influences the estimated ISA. Along with these comparisons with per-pixel models, the sub-pixel model was proposed as an alternative approach for a spatio-temporal model. This approach overcomes the mixed pixel problem when estimating annual proportional ISA and can handle with a coarse spatial resolution of MODIS compared to higher resolution remotely sensed data such as Landsat and SPOT.

# 2. Materials and Methods
## 2.1. Study Area

  In the JMA, ISA has rapidly increased over several decades [@Pravitasari2015a; @Hudalah2012a; @Pravitasari2014]. The JMA includes Jakarta, the capital city of Indonesia, and its suburban area and consists of the capital special province (DKI Jakarta), five municipalities (Tangerang, Tangerang Selatan, Depok, Bekasi, and Bogor) and three districts (Tangerang, Bekasi, and Bogor) (Figure 1). Its population agglomeration is one of the highest in the world [@Schneider2009b] and it has experienced rapid urban expansion [@Pravitasari2015a]. This region had a population of 27.2 million people in 2011 [@Hudalah2012a] and covers a total area of 6659 km^2^. Although the metropolitan core is located in DKI Jakarta, which is the political and economic center of the country, the population in the suburbs has risen dramatically since the 1980s [@Hudalah2012a]. While the finance, service and commercial sectors are still concentrated in DKI Jakarta, the manufacturing sector has expanded into suburban areas, resulting in land use transformations away from agricultural land into ISA [@Hudalah2012a]. The population growth in the suburban areas has been considerable and the urban expansion has been less controlled compared to the DKI Jakarta [@Rustiadi2013c]. As this area is located in a tropical region, high cloud cover has prevented continuous observations of land cover dynamics using widely available optical data.

## 2.2. Data

  This research used 16-days composite EVI data provided by the MOD13Q1 product (Version 5) observed by the MODIS instruments on board the TERRA satellite. This product is derived from observed reflectance data corrected for molecular scattering, ozone absorption and aerosols and has a 231.7 m pixel resolution over the JMA. EVI is considered to have high biomass sensitivity and vegetation monitoring capacity compared to the Normalized Difference Vegetation Index (NDVI) [@Huete2002]. As EVI was developed to measure of vegetation activity it can be used to estimate land covers to investigate annual characteristics of EVI change, because its temporal profile associated with vegetation activity can be regarded as useful land cover information [@Clark2012c @Clark2010e @Sanchez-Cuervo2012d ; @Schneider2010]. The temporal profile of EVI in ISA may confuse with water body due to low albedo from ground surface in non-vegetated areas, and such misidentification will lead to lower accuracy of the results. Thus apparent water surface shown in MODIS water mask product (MOD44W) in the same spatial scale of MOD13Q1 layers were masked from the study area. These masked areas are located on the northwest part and northeast edge of the study area, mainly representing as aquaculture ponds. Barelands that can be seen, including non-paved roads, are limited in the study area, thus they were not considered in this research.


```{r fig1, echo=FALSE,fig.width=9,fig.cap=fig$cap("", "Study area.")}
knitr::include_graphics('./Fig1.pdf', auto_pdf = TRUE)
```

    
  Pixels indicated with a good or marginal flag on the MOD13Q1 pixel reliability layer were extracted from original EVI time series resulting in a 36.3% total data loss due to cloud cover. Despite removing unreliable pixels, other studies have shown that noise may remain due to the atmospherically bias, surface anisotropic, and sensor problems [@Jonsson2004f]. To deal with the interpolation of missing valued pixels and the reduction of such noise, the double logistic function provided by TIMESAT was applied to the data [@Jonsson2004f; @Eklundh2012]. This fits the data (in this case the EVI time series data) to smooth continuous asymmetric curves and has been found to be well suited for enhancing time-series patterns from data using existing reliable pixel values [@Eklundh2012]. As the aim was to produce annual ISA maps, the post-filtered EVI time series at each pixel was split into 13 annual patterns consisting of 16-days composited 23 values.

  Reference data were collected at 1000 randomly chosen areas in the same size as MOD13Q1 EVI pixels (1.58% of the study area in total). The proportion of seven different land cover classes (ISA, Paddyfield, Cultivated, Trees, Grass, Bare, and Water) was recorded by a visual inspection of historical VHR images such as Quickbird provided by DigitalGlobe in GE using 5% intervals from 0% to 100%. With the selected 1000 squared lines surrounding the chosen areas overlayed in GE, seven land covers were visually interpreted from available historical VHR images in each year. Duplicated data in a same year at the same area were excluded. Land covers were not recorded when the VHR images were not found within the chosen areas. Reference data were double checked to minimize human errors. A number of other studies have built reference data from GE and have successfully overcame difficulties of collection of reference data [@Clark2012c @Clark2010e @Sanchez-Cuervo2012d ; @Tsutsumida2015; @Kobayashi2013; @Kontgis2014; @Schneider2012a]. To focus on ISA, the other six land cover classes were summarized into Other class. While 13,000 samples (1000 grid \× 13 years) were expected in total, in some places, in some years, historical VHR images were not available in GE. The final reference dataset included 4561 data points over 1000 locations and 13 years (Table 1). The reference data were then randomly divided into training and validation samples (50% each).  
    
    
  
  
```{r load data, message=FALSE, warning=FALSE, echo = FALSE}

Year <- 2001:2013

  
## loda data
  bnd_ras <- raster("./data/bnd.tif") #Boundary data
  ii <- which(!is.na(bnd_ras[])) #extract index where values exist
  dat_num <- sum(bnd_ras[],na.rm = T) #number of existing values 
  load("./data/GEsample1000_evidl.rda") #Vlaidation / Training data with 23 variables 16 day returns in EVI
  load("./data/evidl_annual_0113.rda") #Annually split EVI data from EVI post-processed data by Double Logistic regression by TIMESAT ("ts.dl.df")
# loads the smoothed image data ts.dl.df 
  bnd.JMA <- readShapePoly("./data/JMA_DKI_bnd.shp", proj4string = CRS("+proj=utm +datum=WGS84"))
  bnd.JMA_latlon <- readShapePoly("./data/JMA_DKI_bnd_wgs84_latlon.shp",proj4string = CRS("+proj=longlat +datum=WGS84") )
  
###water mask
### MOD44W
  mask <- raster("./data/HDF4_EOS.EOS_GRID.MOD44W.A2000055.h28v09.005.2009212174649.hdf.MOD44W_250m_GRID.water_mask.tif")
#  mask <- raster("mask_mod44w.tif")
  mask[mask == 1 ] <- NA
  mask[!is.na(mask[])] <- 1
 
###0.3 Reference data  ---------------------     
#omit the point which does not contain EVI data from reference data
#"sampling" is the whole reference data with land cover proportions and annual EVI data (23 observations)
  nacount <- function(x){sum( is.na(x) ) }
  appl <- apply(GEsample1000_evidl@data,1,nacount)
  n <- which(appl==0)
  smp.pt <- GEsample1000_evidl[n, ]
  tmp <- extract(mask, smp.pt)   ##water masked
  smp.pt <- smp.pt[!is.na(tmp), ]

```


\begin{center}
{Table 1. Number of reference data in each year.}
\end{center}

```{r eval=T, echo=F, message=F, warning=F, results='asis'}
## Table 1------------------------------------
## Number of reference data in each year
 
   tab1 <- array(table(smp.pt@data$Year))
   tab1[14] <- sum(tab1)
   names(tab1) <- c(2001:2013, "Total")
  tab1 <- t(data.frame(tab1))
  rownames(tab1) <- NULL
   kable(tab1, col.names = c(2001:2013, "Total"), booktabs = T, format = 'markdown', caption = " Number of reference data in each year.") 

   
```

```{r eval=T, echo=F, message=F, warning=F, results='asis'}
###0.4 Training/Validation sample preparation  ---------------------  
### Just looking at the Impervious class here
#For Soft classification
#use Impervious column
#For Hard classification
#pick up only over p% land cover
#p=25 (model B), 50 (model C), 75 (model D)
  p <- 25
  smp.pt@data$Imp25p <- NA
  cond <- (smp.pt@data$Impervious >= p)
  smp.pt@data[cond,]$Imp25p <- "Impervious"
  cond <- (smp.pt@data$Impervious < p)
  smp.pt@data[cond,]$Imp25p <- "Others"

  p <- 50
  smp.pt@data$Imp50p <- NA
  cond <- (smp.pt@data$Impervious >= p)
  smp.pt@data[cond,]$Imp50p <- "Impervious"
  cond <- (smp.pt@data$Impervious < p)
  smp.pt@data[cond,]$Imp50p <- "Others"

  p <- 75
  smp.pt@data$Imp75p <- NA
  cond <- (smp.pt@data$Impervious >= p)
  smp.pt@data[cond,]$Imp75p <- "Impervious"
  cond <- (smp.pt@data$Impervious < p)
  smp.pt@data[cond,]$Imp75p <- "Others"

### create validation and trianing datasets
## random 50% of reference data as training data (random forest)
  per <- 0.5
  randomsp <- sample(length(smp.pt), length(smp.pt) * per, replace = F)
  randomsp2 <- setdiff((1:length(smp.pt)), randomsp)
## training data
  training.pt <- smp.pt[sort(randomsp), ]
## validation data
  valid.pt <- smp.pt[sort(randomsp2), ]
```
  
  
## 2.3. Analysis

  This research used a sub-pixel RF classification. This model was compared with per-pixel RF classifiers. RF is an ensemble learning approach that aggregates regression or classification tree predictors such that each tree is individually trained on a bootstrapped sample of the training data with a random feature selection [@Gislason2006a; @Balzter2015; @Breiman2001; @Liaw2002a; @Senf2012c]. The random feature selection is conducted so as to decrease correlations between the trees. The individual trees constructed from selected training data are only used for analyses of regression/classification and remainders, which are called “out-of-bag” (OOB) data, are used for accuracy assessment [@Breiman2001]. Results are determined so as to minimize the OOB error rate constructed by the predicted values and OOB data. The error rates are calculated from the mean of squared errors (MSE) for all trees for regression, or misclassification rates for classification. The results are produced by the average of the predicted values of all selected trees for regression or by the most categorized class (a majority vote) for classification [@Breiman2001]. Using OOB bootstrap samples, outputs of RF produce the percentage of variance explained for regression and the error rate for classification. Variable importance which shows how each variable contributes to the predicted model are also estimated, measured by the total decrease in node impurities from splitting on the variable based on the averaged residual sum of squares for regression, or the Gini index for classification over all trees [@Liaw2002a].

  In this research, a RF regression was constructed using proportional reference data, which is:

* __Model _ISAsub_ __: RF regression using ISA proportions as the dependent variable (sub-pixel classification approach)

  In order to classify the annual patterns of EVI, input variables were selected from the 23 annual post-filtered EVI values. As 299 EVI time series during 2001–2013 was split into 13 annual patterns consisting of 23 values, such variables can be regarded as EVI values in every 16 days (Day of year (DOY) 1, 17, . . . , 353) in a year. Variable selection from 23 variables were determined by the *rf.modelSel* function in *rfUtilities* package in R [@Evans2002r]. The rf.modelSel function selects input variables in terms of a model improvement ratio (MIR) calculated from ranked importance of variables divided by the maximum value of the importance among all variables. Variables are only retained when its MIR is larger than a threshold, which is in the range 0–1, and the selected variables are finally determined when the percentage of variance explained is maximized (the MSE is minimized) among all tests [@Murphy2010].

  To confirm the influence of each variable importance, relative importance measures of variables were calculated from each importance of variable divided by the maximum measure of importance among all 23 variables for Model *ISAsub*. Such measures tell the degree of contribution of variables to the model and it helps understanding of the model.

  RF classifiers using crisp reference data created by different thresholds of ISA proportion were also assembled for the comparison with the sub-pixel model. To investigate the differences caused by different thresholds in per-pixel analyses, three thresholds were applied: 25%, 50%, and 75%. Thus the models examined by per-pixel approach were:

* __Model _ISAp25_ __: RF classifier using the Boolean data defined as greater than 25% ISA in the reference pixel (per-pixel classification approach)
* __Model _ISAp50_ __: RF classifier using the Boolean data defined as greater than 50% ISA in the reference pixel (per-pixel classification approach)
* __Model _ISAp75_ __: RF classifier using the Boolean data defined as greater than 75% ISA in the reference pixel (per-pixel classification approach)

  Annual ISA maps for each year from 2001 to 2013 were predicted from the results of each model. The RF analyses were undertaken in R using the *randomForest* package [@Liaw2002a]. The RF models require some initial parameters to be set: the number of trees (*ntree*) and the number of variables to be randomly sampled as candidates at each tree (*mtry*). The larger the number of ntree parameter, the more stable the outcome becomes, although the calculation time increases. In this case, it was set to 5000. The randomForest package includes a function (*tuneRF*) to determine the optimal number of mtry which suggested *mtry* = 4 in all models. Other parameters are used in the default setting in the *randomForest* function.

  The RF outputs contain assessments of the model performance by OOB error rate for classification. Although the OOB error rate seems to be unbiased [@Breiman2001], several previous studies found such rate often tends to overestimate compared with a holdout validation assessment in some conditions [@Rodriguez-Galiano2012; @Mitchell2011] and did so in this analysis. It is important that users evaluate the utility of the mapped outputs for their intended applications [@Stehman1998b] and thus traditional accuracy assessments were implemented using holdout samples of the validation data. R-squared and the percentage of root mean square error (%RMSE) of the outputs from Model *ISAsub* were calculated from the validation data as the accuracy measures. For Models *ISAp25*, *ISAp50*, and *ISAp75*, a confusion matrix was constructed and user’s, producer’s, and overall accuracies were calculated. Those assessments are reported as a model assessment and map-based assessment for each.



```{r echo=FALSE,fig.width=9,fig.cap=fig$cap("", "A flowchart of this research.")}
knitr::include_graphics('./Fig2.pdf', auto_pdf = TRUE)
```
  
  In order to estimate the total area of ISA from Model *ISAsub*, the area size of ISA was calculated by multiplying the area of impervious pixel by the proportion of the ISA in each pixel:

  $$ Area =  \sum_{i=0}^n I_i p_i$$       

where *Area* is the total area of ISA, *n* is the number of pixels estimated as ISA, I was the area of the pixel estimated as ISA, and *p* is the ISA proportion predicted by Model *ISAsub*. The simple approach of counting the pixels classified as ISAs [@Clark2012c ] was utilized for Models *ISAp25*, *ISAp50*, and *ISAp75*. The total amount of ISA in the annual maps produced by each model should not show oscillatory or irregular change [@Clark2010e ]. Therefore the temporal trends in total ISA during the period 2001 to 2013 were evaluated using a simple regression approach (e.g., [@Clark2012c ]). A flowchart of this overall approach is shown in Figure 2.

#3. Results
##3.1. Model Performance with Different Input Variables

 
```{r eval=T, echo=F, message=F, warning=F, results='asis'}
##1. Model ISAsub.RF regression for Impervous, Proportion-------------------------------------
  vi.t <- training.pt@data[ ,18:40]
  vi.v <- valid.pt@data[ ,18:40]
## create dataset for RF implementation
  Class.t <- training.pt@data$Impervious
  smp.t <- cbind(Class.t, vi.t)
  Class.v <- valid.pt@data$Impervious
  smp.v <- cbind(Class.v, vi.v)


## Implement Random Forest
  ##rfUtilities
  ans.modelsel <- rf.modelSel(smp.t[,-1], Class.t, final = TRUE, plot.imp = TRUE, mtry = 4,ntree = 5000 ) 
 # ans.modelsel
 # zapsmall(ans.modelsel$test[,2], 3)

  ##In a paper, results using 23 variables is replaced the actual results used for mapping.
#   $rf.final
#   
#   Call:
#     randomForest(x = xdata[, sel.vars], y = ydata, ntree = 5000,      mtry = 4, importance = TRUE) 
#   Type of random forest: regression
#   Number of trees: 5000
#   No. of variables tried at each split: 4
#   
#   Mean of squared residuals: 415.4573
#   % Var explained: 58.55
#   
#   $selvars
#   [1] "V1"  "V2"  "V3"  "V4"  "V5"  "V6"  "V7"  "V8"  "V9"  "V10" "V11" "V12" "V13" "V14" "V15" "V16" "V17"
#   [18] "V18" "V19" "V20" "V21" "V22" "V23"
#   
#   $test
#   THRESHOLD    VAREXP      MSE NPARAMETERS
#   1 0.0000000 0.5849171 418.1826          23
#   2 0.2626979 0.5825596 420.1878          17
#   3 0.5447453 0.5655656 436.4652          12
#   4 0.6544970 0.5535195 448.9181           6
#   
#   $importance
#   importance
#   V1   0.2472250
#   V2   0.3085729
#   V3   0.4236582
#   V4   0.3238941
#   V5   0.3803062
#   V6   0.6081027
#   V7   0.8789002
#   V8   1.0000000
#   V9   0.7192798
#   V10  0.7042107
#   V11  0.6432100
#   V12  0.6479686
#   V13  0.6124709
#   V14  0.5447453
#   V15  0.6785798
#   V16  0.6610255
#   V17  0.6126648
#   V18  0.2781709
#   V19  0.1739634
#   V20  0.1572477
#   V21  0.1606567
#   V22  0.1571676
#   V23  0.1388819
#   
#   $parameters
#   $parameters[[1]]
#   [1] "V1"  "V2"  "V3"  "V4"  "V5"  "V6"  "V7"  "V8"  "V9"  "V10" "V11" "V12" "V13" "V14" "V15" "V16" "V17"
#   [18] "V18" "V19" "V20" "V21" "V22" "V23"
#   
#   $parameters[[2]]
#   [1] "V2"  "V3"  "V4"  "V5"  "V6"  "V7"  "V8"  "V9"  "V10" "V11" "V12" "V13" "V14" "V15" "V16" "V17" "V18"
#   
#   $parameters[[3]]
#   [1] "V6"  "V7"  "V8"  "V9"  "V10" "V11" "V12" "V13" "V14" "V15" "V16" "V17"
#   
#   $parameters[[4]]
#   [1] "V7"  "V8"  "V9"  "V10" "V15" "V16"
#   
#   
#   >   zapsmall(ans.modelsel$test[,2],3)
#   [1] 0.585 0.583 0.566 0.554

  
```


```{r eval=T, echo=F, message=F, warning=F, results='asis'}
###4 Model implementations ------------------------

###model ISAsub implementation#
#  sample_d.tune <- tuneRF(smp.t[,-1],smp.t[,1],doBest = T)
  ans.modelA <- randomForest(Class.t~.,data = smp.t, mtry = 4,ntree = 5000,na.action = na.exclude)
 
#print(ans.modelA)
  ## Original result ##
  # Call:
  #   randomForest(formula = Class.t ~ ., data = smp.t, mtry = 4, ntree = 5000,      na.action = na.exclude) 
  # Type of random forest: regression
  # Number of trees: 5000
  # No. of variables tried at each split: 4
  # 
  # Mean of squared residuals: 415.9775
  # % Var explained: 58.49
  
 

## Model ISAp25: Impervious is over 25% of impervious surface rate, the left is Others-------------------
#  xtabs(~smp.pt@data$Imp25p)
#Impervious     Others 
#2060       2553 
## create data frames for RF implementation
  vi.t <- training.pt@data[,18:40]
  Class.t <- training.pt@data$Imp25p
  smp.t <- cbind(Class.t,vi.t)
  vi.v <- valid.pt@data[,18:40]
  Class.v <- valid.pt@data$Imp25p
  smp.v <- cbind(Class.v,vi.v)


### Implement Random Forest
## RF needs 2 params
# mtry and ntree
# these are estimated by tuneRF
# BUT it is sensitive so it gives an idea of mtry 
#sample_d.tune<-tuneRF(smp.t.r[,-1],smp.t.r[,1],doBest = T)

  ans.modelB <- randomForest(Class.t~.,data = smp.t, mtry = 4,ntree = 5000,na.action = na.exclude)
 
# print(ans.modelB)
  
# Call:
#   randomForest(formula = Class.t ~ ., data = smp.t, mtry = 4, ntree = 5000,      na.action = na.exclude) 
# Type of random forest: classification
# Number of trees: 5000
# No. of variables tried at each split: 4
# 
# OOB estimate of  error rate: 20.66%
# Confusion matrix:
#   Impervious Others class.error
# Impervious        776    256   0.2480620
# Others            215   1033   0.1722756


##  Model ISAp50: Impervious is over 50% of impervious surface rate, the left is Others -----------------------------
## create dataset for RF implementation
Class.t <- training.pt@data$Imp50p
smp.t <- cbind(Class.t,vi.t)
Class.v <- valid.pt@data$Imp50p
smp.v <- cbind(Class.v,vi.v)


## Implement Random Forest
#  sample_d.tune<-tuneRF(smp.t[,-1],smp.t[,1],doBest = T)
ans.modelC <- randomForest(Class.t~.,data = smp.t, mtry = 4,ntree = 5000,na.action = na.exclude)

#print(ans.modelC)

# Call:
#   randomForest(formula = Class.t ~ ., data = smp.t, mtry = 4, ntree = 5000,      na.action = na.exclude) 
# Type of random forest: classification
# Number of trees: 5000
# No. of variables tried at each split: 4
# 
# OOB estimate of  error rate: 15.13%
# Confusion matrix:
#   Impervious Others class.error
# Impervious        452    216  0.32335329
# Others            129   1483  0.08002481


## Model ISap75: Impervious is over 75% of impervious surface rate, the left is Others -----------------------------
## create dataset for RF implementation
Class.t <- training.pt@data$Imp75p
smp.t <- cbind(Class.t,vi.t)
Class.v <- valid.pt@data$Imp75p
smp.v <- cbind(Class.v,vi.v)


## Implement Random Forest
#sample_d.tune <- tuneRF(smp.t[,-1],smp.t[,1],doBest = T)
ans.modelD <- randomForest(Class.t~.,data = smp.t, mtry = 4,ntree = 5000,na.action = na.exclude)

#print(ans.modelD)

# Call:
#   randomForest(formula = Class.t ~ ., data = smp.t, mtry = 4, ntree = 5000,      na.action = na.exclude) 
# Type of random forest: classification
# Number of trees: 5000
# No. of variables tried at each split: 4
# 
# OOB estimate of  error rate: 10.79%
# Confusion matrix:
#   Impervious Others class.error
# Impervious        218    146  0.40109890
# Others            100   1816  0.05219207

  
```


```{r eval=T, echo=F, message=F, warning=F, results='asis'}
# This chunk is for Table 3  --------------------------------------------------------------------
### Compared with 4 summarised phenological indices models ###
## create dataset for RF implementation
Class.t <- training.pt@data$Impervious
smp.t.r <- cbind(Class.t,vi.t)
Class.v <- valid.pt@data$Impervious
smp.v.r <- cbind(Class.v,vi.v)

### calculate mean, min, max, sd of time series
smp.t.r$mean <- apply(smp.t.r[, 2:24],1,mean)
smp.t.r$max <- apply(smp.t.r[,2:24],1,max)
smp.t.r$min <- apply(smp.t.r[,2:24],1,min)
smp.t.r$sd <- apply(smp.t.r[,2:24],1,sd)

smp.v.r$mean <- apply(smp.v.r[, 2:24],1,mean)
smp.v.r$max <- apply(smp.v.r[,2:24],1,max)
smp.v.r$min <- apply(smp.v.r[,2:24],1,min)
smp.v.r$sd <- apply(smp.v.r[,2:24],1,sd)

smp.t.r <- smp.t.r[,c(1,25:28)]
smp.v.r <- smp.v.r[,c(1,25:28)]

ts.dl.df.4pheno <- data.frame(apply(ts.dl.df,1,mean),  apply(ts.dl.df,1,max), apply(ts.dl.df,1,min), apply(ts.dl.df,1,sd))
names(ts.dl.df.4pheno) <- c("mean", "max", "min", "sd")

## Implement Random Forest
##model ISAsub
#  sample_d.tune <- tuneRF(smp.t.r[,-1],smp.t.r[,1],doBest = T)
ans.modelA.r <- randomForest(Class.t~.,data = smp.t.r, mtry = 4,ntree = 5000,na.action = na.exclude)
#print(ans.modelA.r)

### Result for Revise using mean,min,max,sd ###
# Call:
#   randomForest(formula = Class.t ~ ., data = smp.t.r, mtry = 4,      ntree = 5000, na.action = na.exclude) 
# Type of random forest: regression
# Number of trees: 5000
# No. of variables tried at each split: 4
# 
# Mean of squared residuals: 472.7278
# % Var explained: 52.83



### Model ISAp25
vi.t <- training.pt@data[,18:40]
Class.t <- training.pt@data$Imp25p
smp.t.r <- cbind(Class.t,vi.t)
vi.v <- valid.pt@data[,18:40]
Class.v <- valid.pt@data$Imp25p
smp.v.r <- cbind(Class.v,vi.v)

### calculate mean, min, max, sd of time series
smp.t.r$mean <- apply(smp.t.r[, 2:24],1,mean)
smp.t.r$max <- apply(smp.t.r[,2:24],1,max)
smp.t.r$min <- apply(smp.t.r[,2:24],1,min)
smp.t.r$sd <- apply(smp.t.r[,2:24],1,sd)

smp.v.r$mean <- apply(smp.v.r[, 2:24],1,mean)
smp.v.r$max <- apply(smp.v.r[,2:24],1,max)
smp.v.r$min <- apply(smp.v.r[,2:24],1,min)
smp.v.r$sd <- apply(smp.v.r[,2:24],1,sd)

smp.t.r <- smp.t.r[,c(1,25:28)]
smp.v.r <- smp.v.r[,c(1,25:28)]


ans.modelB.r <- randomForest(Class.t~.,data = smp.t.r, mtry = 4, ntree = 5000, na.action = na.exclude)
#print(ans.modelB.r)

# Call:
#   randomForest(formula = Class.t ~ ., data = smp.t.r, mtry = 4,      ntree = 5000, na.action = na.exclude) 
# Type of random forest: classification
# Number of trees: 5000
# No. of variables tried at each split: 4
# 
# OOB estimate of  error rate: 24.3%
# Confusion matrix:
#   Impervious Others class.error
# Impervious        754    278   0.2693798
# Others            276    972   0.2211538


### Model ISAp50 ###
## create dataset for RF implementation
Class.t <- training.pt@data$Imp50p
smp.t.r <- cbind(Class.t,vi.t)
Class.v <- valid.pt@data$Imp50p
smp.v.r <- cbind(Class.v,vi.v)

### calculate mean, min, max, sd of time series
smp.t.r$mean <- apply(smp.t.r[, 2:24],1,mean)
smp.t.r$max <- apply(smp.t.r[,2:24],1,max)
smp.t.r$min <- apply(smp.t.r[,2:24],1,min)
smp.t.r$sd <- apply(smp.t.r[,2:24],1,sd)

smp.v.r$mean <- apply(smp.v.r[, 2:24],1,mean)
smp.v.r$max <- apply(smp.v.r[,2:24],1,max)
smp.v.r$min <- apply(smp.v.r[,2:24],1,min)
smp.v.r$sd <- apply(smp.v.r[,2:24],1,sd)

smp.t.r <- smp.t.r[,c(1,25:28)]
smp.v.r <- smp.v.r[,c(1,25:28)]

## Implement Random Forest
#  sample_d.tune<-tuneRF(smp.t[,-1],smp.t[,1],doBest = T)
ans.modelC.r <- randomForest(Class.t~.,data = smp.t.r, mtry = 4,ntree = 5000,na.action = na.exclude)
#print(ans.modelC.r)

# Call:
#   randomForest(formula = Class.t ~ ., data = smp.t.r, mtry = 4,      ntree = 5000, na.action = na.exclude) 
# Type of random forest: classification
# Number of trees: 5000
# No. of variables tried at each split: 4
# 
# OOB estimate of  error rate: 16.84%
# Confusion matrix:
#   Impervious Others class.error
# Impervious        447    221   0.3308383
# Others            163   1449   0.1011166



#model ISAp75
## create dataset for RF implementation
Class.t <- training.pt@data$Imp75p
smp.t.r <- cbind(Class.t,vi.t)
Class.v <- valid.pt@data$Imp75p
smp.v.r <- cbind(Class.v,vi.v)

#### for revise
### calculate mean, min, max, sd of time series
smp.t.r$mean <- apply(smp.t.r[, 2:24],1,mean)
smp.t.r$max <- apply(smp.t.r[,2:24],1,max)
smp.t.r$min <- apply(smp.t.r[,2:24],1,min)
smp.t.r$sd <- apply(smp.t.r[,2:24],1,sd)

smp.v.r$mean <- apply(smp.v.r[, 2:24],1,mean)
smp.v.r$max <- apply(smp.v.r[,2:24],1,max)
smp.v.r$min <- apply(smp.v.r[,2:24],1,min)
smp.v.r$sd <- apply(smp.v.r[,2:24],1,sd)

smp.t.r <- smp.t.r[,c(1,25:28)]
smp.v.r <- smp.v.r[,c(1,25:28)]


## Implement Random Forest
ans.modelD.r <- randomForest(Class.t~.,data = smp.t.r, mtry = 4,ntree = 5000,na.action = na.exclude)
#print(ans.modelD.r)

# Call:
#   randomForest(formula = Class.t ~ ., data = smp.t.r, mtry = 4,      ntree = 5000, na.action = na.exclude) 
# Type of random forest: classification
# Number of trees: 5000
# No. of variables tried at each split: 4
# OOB estimate of  error rate: 11.84%
# Confusion matrix:
#   Impervious Others class.error
# Impervious        193    171  0.46978022
# Others             99   1817  0.05167015


```


 The selection of input variables was investigated by *rf.modelSel* function for sub-pixel analysis, resulting the highest percentage of variance explained (`r sprintf('%.1f', 100 * (1 - sum((ans.modelA$y - ans.modelA$pred )^2) / sum((ans.modelA$y - mean(ans.modelA$y))^2)))` %) when using all 23 variables (Table 2). Thus, all 23 variables were used for latter procedures. Multi-collinearity among the 23 variables was not found when investigated using the *multi.collinear* function in *rfUtilities* package as well [@Evans2002r].

  For further comparison, two types of input variables were considered as: (i) all 23 variables; and (ii) four phenological indices summarized as minimum, maximum, mean, and standard deviation of 23 values for Model *ISAsub*, *ISAp25*, *ISAp50*, and *ISAp75*. Table 3 showed that models using 23 variables yielded higher variance explained for Model *ISAsub* and lower OOB error rate for Model *ISAp25*, *ISAp50*, and *ISAp75*, than those using four phenological indices. It suggests all models using 23 variables showed the best performance.  
 
\begin{center}
{Table 2. Variable selection by rf.modelSel function for sub-pixel analysis.}
\end{center}

```{r eval=T, echo=F, message=F, warning=F, results='asis'}
###tab2----------------------
  tab2 <- cbind(ans.modelsel$test[, 4], zapsmall(ans.modelsel$test[, 2] *100, 3) )
  colnames(tab2) <- c("Number of parameters", "Variable explained (%)")
  rownames(tab2) <- c("VAR1,2,..., and 23", "VAR2,3,..., and 18", "VAR6,7,...,17", "VAR8,9,10,15, and 16")
   kable(tab2, col.names = colnames(tab2), booktabs = T, format = 'markdown') 

```
  
 
\begin{center}
{Table 3. Comparison of results using annual 23 values of enhanced vegetation index (EVI) and extracted four phenological indices for Model ISAsub, ISAp25, ISAp50, and ISAp75.}
\end{center}
  
  
```{r eval=T, echo=F, message=F, warning=F, results='asis'}
### table 3
tab3 <- matrix(NA, nrow=2, ncol=4)
rownames(tab3) <- c("23 variables", "4 phenological indices")
colnames(tab3) <- c("Model ISAsub (Variance Explained) (%)",
                 "Model ISAp25 (OOB Error Rate) (%)",
                 "Model ISAp50 (OOB Error Rate) (%)",
                 "Model ISAp75 (OOB Error Rate) (%)")

tab3[1,1] <- 100 * (1 - sum((ans.modelA$y - ans.modelA$pred )^2) / sum((ans.modelA$y - mean(ans.modelA$y))^2))

oob.B <- oob_matrix(ans.modelB)
tab3[1,2] <- (1 - (oob.B[1,1] + oob.B[2,2]) / oob.B[3,3]) * 100
oob.C <- oob_matrix(ans.modelC)
tab3[1,3] <- (1 - (oob.C[1,1] + oob.C[2,2]) / oob.C[3,3]) * 100
oob.D <- oob_matrix(ans.modelD)
tab3[1,4] <- (1 - (oob.D[1,1] + oob.D[2,2]) / oob.D[3,3]) * 100

tab3[2,1] <- 100 * (1 - sum((ans.modelA.r$y - ans.modelA.r$pred )^2) / sum((ans.modelA.r$y - mean(ans.modelA.r$y))^2))
oob.B.r <- oob_matrix(ans.modelB.r)
tab3[2,2] <- (1 - (oob.B.r[1,1] + oob.B.r[2,2]) / oob.B.r[3,3]) * 100
oob.C.r <- oob_matrix(ans.modelC.r)
tab3[2,3] <- (1 - (oob.C.r[1,1] + oob.C.r[2,2]) / oob.C.r[3,3]) * 100
oob.D.r <- oob_matrix(ans.modelD.r)
tab3[2,4] <- (1 - (oob.D.r[1,1] + oob.D.r[2,2]) / oob.D.r[3,3]) * 100
 
  kable(zapsmall(tab3, 3), booktabs = T, format = 'markdown') 


```

## 3.2. Sub-Pixel Classification

```{r eval=T, echo=F, message=F, warning=F, results='hide'}
## This chunk is for preparation of Fig 3
## Random Forest prediction
pred.all.A <- predict(ans.modelA,ts.dl.df,na.rm = T)
## Annual ISA mappings
 stk.A <- stack()
 for(j in (1:13)){
   start <- dat_num*(j-1)+1
   end <- dat_num*j
   raster <- raster(bnd_ras)
   raster[ii] <- pred.all.A[start:end]
   eval(parse(text = paste("img",j," <- raster",sep = "")))
eval(parse(text = paste("writeRaster(img",j,",filename = 'MOD09Q1_SG4_RF_ImperviousProportion",j,"_result.tif',format = 'GTiff',overwrite = TRUE)",sep = "")))
   stk.A <- stack(stk.A,raster)
 }

 names(stk.A) <- c("Y2001","Y2002","Y2003","Y2004","Y2005","Y2006","Y2007","Y2008","Y2009","Y2010","Y2011","Y2012","Y2013")
 #rm(pred.all.A)


##accuracy of global model ISAsub
  pred.A <- predict(ans.modelA,smp.v,na.rm = T)
  
  Class.v <- valid.pt@data$Impervious
  smp.v <- cbind(Class.v, vi.v)

  rsqA <- 1 - sum((Class.v - pred.A)^2)/sum((Class.v -mean(Class.v))^2)
  rmseA <- sqrt( mean( (pred.A - Class.v)^2 , na.rm = TRUE ) )
##accuracy of annual model ISAsub
  accu.P <- annual_confusion_matrix_prop(valid.pt, stk.A)

```

  The annual maps of ISA proportion from Model *ISAsub* are shown in Figure 3. The distribution of areas with a high proportion of ISA can be found around DKI Jakarta, as well as the center of Tangerang, Bekasi, and Bogor municipalities. Gradual expansion of such areas can be seen in the peripheral areas of those urban cores over 13 years. Relative importance measures of input variables were shown that 6th–17th variables (DOY 80–256), indicating over 0.5 of relative importance measures, highly contribute to the model, while others do not (Figure 4). The 15th variable (DOY 224) is the highest importance among all variables and the 10th variable (DOY 144) is the second, while 22nd variable (DOY 336) is the lowest and 21st (DOY 320) is the second lowest. For the model assessment, the R-squared is `r sprintf('%.2f', as.numeric(rsqA))` and %RMSE is `r sprintf('%.2f', as.numeric(rmseA))`. The hexagon plot shades each cell by the number of data points in those value ranges (Figure 5) and indicates variations between validation and predicted data. Many predicted values tend to underestimate at larger ISA proportions, while overestimate at smaller ISA proportions compared to ground values. The annual accuracy assessments of produced maps shown in Table 4 indicate that the R-squared ranged from `r sprintf('%.2f', range(unlist(accu.P$rsqP))[1])`  to `r sprintf('%.2f', range(unlist(accu.P$rsqP))[2])` , and %RMSE was from `r sprintf('%.2f', range(unlist(accu.P$rmseP))[1])` to `r sprintf('%.2f', range(unlist(accu.P$rmseP))[2])`. Significant statistical relationships between variations of R-squared and %RMSE and between such variations and numbers of validation data were not found.



```{r eval=T, echo=F, message=F, warning=F, results='asis', fig.width=16, fig.height=12, fig.cap=fig$cap("", "Annual impervious surface area (ISA) proportions estimated by Model ISAsub.")}

##Fig3--------------------------------------
  proj.wgs84 <- "+proj=longlat +datum=WGS84 +no_defs"
  stk.A.latlon <- projectRaster(from=stk.A, crs=proj.wgs84)
  l2 = list("SpatialPolygonsRescale", layout.north.arrow(), offset = c(107.2,-6.05), 
            scale = 0.1, which = 13)
  l3 = list("SpatialPolygonsRescale", layout.scale.bar(), offset = c(107.04,-6.72), 
            scale = 0.226, fill=c("black"), which = 13)
  l4 = list("sp.text", c(107.04,-6.75), "0", which=13)
  l5 = list("sp.text", c(107.24,-6.75), "50 km", which=13)
  
 spplot(stk.A.latlon,  par.strip.text=list(cex=2), 
                    names.attr = Year, 
                    col.regions = colorRampPalette(c("#FFFFFF","#CCE5FF","#00CCCC","#000099","#000000")),
                    colorkey=list(at=seq(0,100,10), labels=list(paste(seq(0,100,20), sep=""), cex=2), space="bottom", tick.number = 2, tck = 2),
                    scales=list( tick.number=2, draw=T,  tck = 0.5, cex=1.0),
                    maxpixels = 1e8,
                    sp.layout=list(l2, l3, l4, l5))  + layer(sp.polygons(bnd.JMA_latlon, lwd=0.5))


```

  

```{r eval=T, echo=F, message=F, warning=F, results='asis', fig.width=9, fig.height=6, fig.cap=fig$cap("", "Relative importance measures of variables for Model ISAsub.")}

### Variable importance
###Figure 4 --------------------------------
  x <- 1:23
  names(x) <- paste0("VAR", 1:23)

  dat <- as.data.frame(cbind(x, importance(ans.modelA)/max(importance(ans.modelA))))
  names(dat) <- c("Variables","Relative importance measure")
  dat2 <- melt(dat,id = "Variables", measure = c("Relative importance measure"))
  p <- ggplot(dat2,aes(x = Variables,y = value, group = variable, colour = "black"))
  p <- p +  geom_line(colour = "black")
  p <- p +  geom_point(colour = "black")
  p <- p +  theme_bw()
  p <- p + scale_x_discrete(breaks = c(1,5,10,15,20,23), labels=c("VAR1", "VAR5", "VAR10", "VAR15", "VAR20", "VAR23"))
  p <- p + coord_cartesian(xlim = NULL)
  p <- p + theme(axis.title.x = element_text(size = 22), axis.title.y = element_text(size = 22)) 
  p <- p + theme(axis.text.x = element_text(size = 22, angle = 90, vjust=0.5), axis.text.y = element_text(size = 22)) 
  p <- p + xlab("")
  p <- p + ylab("Relative importance measure")
  p <- p + theme(legend.position = "none")
  p

```
  

  
```{r eval=T, echo=F, message=F, warning=F, results='asis', fig.width=9, fig.height=7, fig.cap=fig$cap("", "The relationship between observed and predicted proportions of ISA under Model ISAsub.")}

### Fig 5----------------
  dat <- data.frame(pred.A,  Class.v)
  names(dat) <- c("Predicted", "Ground")
  p <- ggplot(dat,aes(x = Ground,y = Predicted))
  p <- p + scale_x_continuous(breaks = c(0,25,50,75, 100, 125))
  p <- p + scale_y_continuous(breaks = c(0,25,50,75, 100, 125))
  p <- p + theme_bw()
  p <- p + theme(axis.text.x = element_text(size = 22), axis.text.y = element_text(size = 22)) 
  p <- p + theme(axis.title.x = element_text(size = 22), axis.title.y = element_text(size = 20))
  p <- p + theme(legend.title = element_text(size = 20), legend.text  = element_text(size = 18)) 
  p <- p + geom_hex(bins=10)
  p <- p + scale_fill_gradientn( colours= c("#EFF3FF", "#6BAED6", "#4292C6", "#2171B5", "#08519C", "#08306B") , limits=c(0,250))
  p <- p + geom_abline(intercept = 0, slope = 1,colour = "red")
  p <- p + annotate("text", x = 85, y = 5, label = paste("R-squared = ",round(rsqA,2), sep=""), size = 8)
  p <- p + annotate("text", x = 85, y = -1, label = paste("%RMSE = ",round(rmseA,2), sep=""), size = 8)
  p
```
         
    
\begin{center}
{Table 4. Annual R-squared and the percentage of root mean square error (\%RMSE) of Model ISAsub during 2001–2013.}
\end{center}

```{r eval=T, echo=F, message=F, warning=F, results='asis'}

## table 4
##Annual accuracy assessment impervious proportion
  tab4 <- data.frame(unlist(accu.P$rsqP),unlist(accu.P$rmseP))
  tab4 <- as.matrix(t(tab4), nrow=2)
  tab4 <- round(tab4, 2)
  colnames(tab4) <- Year
  rownames(tab4) <- c("R-squared","%RMSE")

  kable(tab4,  booktabs = T, format = 'markdown')
  
```

## 3.3. Per-Pixel Classification


```{r eval=T, echo=F, message=F, warning=F, results='asis'}

## Model ISAp25: Impervious is over 25% of impervious surface rate, the left is Others-------------------
#  xtabs(~smp.pt@data$Imp25p)
#Impervious     Others 
#2060       2553 
## create data frames for RF implementation
  vi.t <- training.pt@data[,18:40]
  Class.t <- training.pt@data$Imp25p
  smp.t <- cbind(Class.t,vi.t)
  vi.v <- valid.pt@data[,18:40]
  Class.v <- valid.pt@data$Imp25p
  smp.v <- cbind(Class.v,vi.v)


### Implement Random Forest
## RF needs 2 params
# mtry and ntree
# these are estimated by tuneRF
# BUT it is sensitive so it gives an idea of mtry 
#sample_d.tune<-tuneRF(smp.t.r[,-1],smp.t.r[,1],doBest = T)

  ans.modelB <- randomForest(Class.t~.,data = smp.t, mtry = 4,ntree = 5000,na.action = na.exclude)

# Call:
#   randomForest(formula = Class.t ~ ., data = smp.t, mtry = 4, ntree = 5000,      na.action = na.exclude) 
# Type of random forest: classification
# Number of trees: 5000
# No. of variables tried at each split: 4
# 
# OOB estimate of  error rate: 20.66%
# Confusion matrix:
#   Impervious Others class.error
# Impervious        776    256   0.2480620
# Others            215   1033   0.1722756

oob.B <- oob_matrix(ans.modelB)
 oa.B  <- (oob.B[1,1] + oob.B[2,2]) / oob.B[3,3] # [1] 0.7934211
#  Impervious   Others total  User
#  Impervious    776.000  256.000  1032 0.752
#  Others        215.000 1033.000  1248 0.828
#  total         991.000 1289.000  2280    NA
#  Producer        0.783    0.801    NA    NA
#  

## RF predict function
pred.modelB <- predict(ans.modelB,smp.v,type = "Class")
tab5b <- confusion_matrix(smp.v$Class,pred.modelB)

#            Impervious   Others Total    User's
# Impervious    787.000  209.000   996 0.7900000
# Others        241.000 1044.000  1285 0.8120000
# Total        1028.000 1253.000  2281 0.0000000
# Producer's      0.766    0.833     0 0.8027181


## Random Forest prediction using all annual patterns
pred.all.modelB <- predict(ans.modelB,ts.dl.df,type = "Class",na.rm = T)
val <- ifelse(pred.all.modelB == "Impervious",1 ,pred.all.modelB)

## annual mapping from prediction result
 stk.B <- stack()
 for(j in (1:13)){
   start <- dat_num*(j-1)+1
   end <- dat_num*j
   raster <- raster(bnd_ras)
   raster[ii] <- val[start:end]
   eval(parse(text = paste("img",j," <- raster",sep = "")))
   #eval(parse(text = paste("writeRaster(img",j,",filename = 'MOD09Q1_SG4_RF_ImperviousProportion",j,"_result.tif',format = 'GTiff',overwrite = TRUE)",sep = "")))
   stk.B <- stack(stk.B,raster)
 }

 names(stk.B) <- c("Y2001","Y2002","Y2003","Y2004","Y2005","Y2006","Y2007","Y2008","Y2009","Y2010","Y2011","Y2012","Y2013")
 rm(pred.all.modelB)
 rm(val)


##  Model ISAp50: Impervious is over 50% of impervious surface rate, the left is Others -----------------------------
## create dataset for RF implementation
Class.t <- training.pt@data$Imp50p
smp.t <- cbind(Class.t,vi.t)
Class.v <- valid.pt@data$Imp50p
smp.v <- cbind(Class.v,vi.v)


## Implement Random Forest
#  sample_d.tune<-tuneRF(smp.t[,-1],smp.t[,1],doBest = T)
ans.modelC <- randomForest(Class.t~.,data = smp.t, mtry = 4,ntree = 5000,na.action = na.exclude)

# Call:
#   randomForest(formula = Class.t ~ ., data = smp.t, mtry = 4, ntree = 5000,      na.action = na.exclude) 
# Type of random forest: classification
# Number of trees: 5000
# No. of variables tried at each split: 4
# 
# OOB estimate of  error rate: 15.13%
# Confusion matrix:
#   Impervious Others class.error
# Impervious        452    216  0.32335329
# Others            129   1483  0.08002481

oob.C <- oob_matrix(ans.modelC)
oa.C <- (oob.C[1,1] + oob.C[2,2]) / oob.C[3,3]   #[1] 0.8486842

# Impervious   Others total  User
# Impervious    452.000  216.000   668 0.677
# Others        129.000 1483.000  1612 0.920
# total         581.000 1699.000  2280    NA
# Producer        0.778    0.873    NA    NA


## For table2: Accuracy assessment
## Revised version uses OOB matrix
## matrix
  pred.modelC <- predict(ans.modelC,smp.v,type = "Class")
  tab5c <- confusion_matrix(smp.v$Class,pred.modelC)

#               Impervious  Others Total    User's
#    Impervious    460.000  131.00   591 0.7780000
#    Others        178.000 1512.00  1690 0.8950000
#    Total         638.000 1643.00  2281 0.0000000
#    Producer's      0.721    0.92     0 0.8645331
#    
   
## Random Forest prediction
 pred.all.modelC <- predict(ans.modelC,ts.dl.df,type = "Class",na.rm = T)
 val <- ifelse(pred.all.modelC=="Impervious",1,pred.all.modelC)

 stk.C <- stack()
 for(j in (1:13)){
   start <- dat_num*(j-1)+1
   end <- dat_num*j
   raster <- bnd_ras
   ii <- which(! is.na(raster[]))
   raster[ii] <- val[start:end]
   eval(parse(text = paste("img",j," <- raster",sep = "")))
   #eval(parse(text = paste("writeRaster(img",j,",filename = 'MOD09Q1_SG4_RF_ImperviousProportion",j,"_result.tif',format = 'GTiff',overwrite = TRUE)",sep = "")))
   stk.C <- stack(stk.C,raster)
 }

 names(stk.C) <- c("Y2001","Y2002","Y2003","Y2004","Y2005","Y2006","Y2007","Y2008","Y2009","Y2010","Y2011","Y2012","Y2013")
 rm(pred.all.modelC)
 rm(val)
#  #levelplot(stk.C,col.regions = colorRampPalette(brewer.pal(9, "YlGnBu")))


## Model ISap75: Impervious is over 75% of impervious surface rate, the left is Others -----------------------------
## create dataset for RF implementation
Class.t <- training.pt@data$Imp75p
smp.t <- cbind(Class.t,vi.t)
Class.v <- valid.pt@data$Imp75p
smp.v <- cbind(Class.v,vi.v)


## Implement Random Forest
#sample_d.tune <- tuneRF(smp.t[,-1],smp.t[,1],doBest = T)
ans.modelD <- randomForest(Class.t~.,data = smp.t, mtry = 4,ntree = 5000,na.action = na.exclude)

# Call:
#   randomForest(formula = Class.t ~ ., data = smp.t, mtry = 4, ntree = 5000,      na.action = na.exclude) 
# Type of random forest: classification
# Number of trees: 5000
# No. of variables tried at each split: 4
# 
# OOB estimate of  error rate: 10.79%
# Confusion matrix:
#   Impervious Others class.error
# Impervious        218    146  0.40109890
# Others            100   1816  0.05219207

oob.D <- oob_matrix(ans.modelD)
oa.D <- (oob.D[1,1] + oob.D[2,2])/oob.D[3,3]    #[1] 0.8921053

# Impervious   Others total  User
# Impervious    218.000  146.000   364 0.599
# Others        100.000 1816.000  1916 0.948
# total         318.000 1962.000  2280    NA
# Producer        0.686    0.926    NA    NA

##For table2: Accuracy assessment
## Revised version uses OOB matrix
  pred.modelD <- predict(ans.modelD,smp.v,type = "Class")
  tab5d <- confusion_matrix(smp.v$Class,pred.modelD)

#   Impervious  Others Total    User's
# Impervious    232.000   95.00   327 0.7090000
#   Others        155.000 1799.00  1954 0.9210000
#   Total         387.000 1894.00  2281 0.0000000
#   Producer's      0.599    0.95     0 0.8903989   


#Random Forest prediction
 pred.all.modelD <- predict(ans.modelD,ts.dl.df,type = "Class",na.rm = T)
 val <- ifelse(pred.all.modelD=="Impervious",1,pred.all.modelD)

 stk.D <- stack()
 for(j in (1:13)){
   start <- dat_num*(j-1)+1
   end <- dat_num*j
   raster <- bnd_ras
   raster[ii] <- val[start:end]
   eval(parse(text = paste("img",j," <- raster",sep = "")))
   #eval(parse(text = paste("writeRaster(img",j,",filename = 'MOD09Q1_SG4_RF_ImperviousProportion",j,"_result.tif',format = 'GTiff',overwrite = TRUE)",sep = "")))
   stk.D <- stack(stk.D,raster)
 }
 names(stk.D) <- c("Y2001","Y2002","Y2003","Y2004","Y2005","Y2006","Y2007","Y2008","Y2009","Y2010","Y2011","Y2012","Y2013")
 rm(pred.all.modelD)
 rm(val)

```

  
  Annual per-pixel ISA maps with over 25%, 50%, and 75% coverage proportion were produced from Models *ISAp25*, *ISAp50*, and *ISAp75*, respectively. These data are overlayed and shown together in Figure 6. It is observed that ISA from Model *ISAp25* is widely distributed more than ISA from Model *ISAp50*, and then *ISAp75*. As with the sub-pixel classification model in Figure 3, most of the ISA from Model *ISAp75* is distributed around the DKI Jakarta and the core of municipalities, while ISA from Model *ISAp25* are widely distributed in the peripheral areas. The gradual expansion of ISA over time can be also observed in all models.  
  
  The results of the model assessment during 2001–2013 are shown in Table 5. Overall accuracies increase as levels of threshold increase; accuracies for *ISAp25*, *ISAp50*, and *ISAp75* were estimated to be `r sprintf('%.2f', tab5b[4,4])`, `r sprintf('%.2f', tab5c[4,4])`, and `r sprintf('%.2f', tab5d[4,4])`, respectively. Regarding category-level accuracy measures, the user’s and producer’s accuracies of ISA class decrease as the thresholds increase. Accuracy of the Other class have the opposite trend compared to ISA: namely that the user’s and producer’s accuracies of Other increase as such thresholds increase. All of the accuracy measures of Other are higher than for ISA.  
  
  The results of the annual accuracy assessments are shown in Table 6. The user’s and producer’s accuracy of ISA for three models in 2007 were calculated but from insufficient numbers of categorized data as ISA in both validated and predicted data. Model *ISAp75* yields the highest overall accuracy among three models, except in 2011, while yields the lowest user’s and producer’s accuracy of ISA except user’s accuracy in 2002, 2003, and 2008 and producer’s accuracy in 2001 and 2007. Model *ISAp25* often yields the highest user’s and producer’s accuracy of ISA class among three models although such trend is not straightforward. No significant statistical relationships were found between the validation data and accuracy measures.  
    

  
```{r eval=T, echo=F, message=F, warning=F, results='asis', fig.width=16, fig.height=12 ,fig.cap=fig$cap("", "Per-pixel based annual ISA maps. ISA estimated by Model ISAp25, ISAp50, and ISAp75 are overlayed.")}

# Fig 6.  -----------------------------------------------------------
Overlay <- stack()
for(y in 1:13){
  image1 <- stk.B[[y]]
  image1[image1==1] <- 25
  image2 <- stk.C[[y]]
  image2[image2==1] <- 50
  image3 <- stk.D[[y]]
  image3[image3==1] <- 75
  
  tmp <- stack(image1,image2,image3)
  tmp.max <- calc(tmp, max)
  tmp.max[tmp.max < 25 ] <- NA
  Overlay <- stack(Overlay, tmp.max)
  rm(tmp);rm(tmp.max);rm(image1);rm(image2);rm(image3)
}

  names(Overlay) <- c("Y2001","Y2002","Y2003","Y2004","Y2005","Y2006","Y2007","Y2008","Y2009","Y2010","Y2011","Y2012","Y2013")

  proj.wgs84 <- "+proj=longlat +datum=WGS84 +no_defs"
  Overlay.latlon <- projectRaster(from=Overlay, crs=proj.wgs84)
  l2 = list("SpatialPolygonsRescale", layout.north.arrow(), offset = c(107.2,-6.05), scale = 0.1, which = 13)
  l3 = list("SpatialPolygonsRescale", layout.scale.bar(), offset = c(107.04,-6.72), scale = 0.226, fill=c("black"), which = 13)
  l4 = list("sp.text", c(107.04,-6.75), "0", which=13)
  l5 = list("sp.text", c(107.24,-6.75), "50 km", which=13)
  
  spplot(Overlay.latlon,  par.strip.text=list(cex=2), 
         names.attr = Year, 
         col.regions =colorRampPalette(c( "#FFFFFF", "#80B1D3", "#FB8072", "#FFFFB3")),
         colorkey=list(at=c(0, 0.1, 25, 50, 75),  labels=list(at=c(13,37,62), labels=c("ISAp25","ISAp50","ISAp75"), cex=1.5), space="bottom"),
         scales=list( tick.number=2, draw=T,  tck = 0.5, cex=1.0),
         maxpixels = 1e8,
         sp.layout=list(l2, l3, l4, l5))  + layer(sp.polygons(bnd.JMA_latlon, lwd=0.5))

```

  
  
\begin{center}
{Table 5. Confusion matrices for model assessments constructed from predicted values and validation data in Model ISAp25, ISAp50, and ISAp75.}
\end{center}
  
```{r eval=T, echo=F, message=F, warning=F, results='asis'}
#### table 5
tab5b.tmp <- tab5b
tab5b.tmp[3,4] <- NA
tab5b.tmp[4,3] <- NA
tab5b.tmp[4,4] <- NA

tab5c.tmp <- tab5c
tab5c.tmp[3,4] <- NA
tab5c.tmp[4,3] <- NA
tab5c.tmp[4,4] <- NA

tab5d.tmp <- tab5d
tab5d.tmp[3,4] <- NA
tab5d.tmp[4,3] <- NA
tab5d.tmp[4,4] <- NA

tab5 <- cbind(zapsmall(tab5b.tmp, 5), cbind(zapsmall(tab5c.tmp, 5), zapsmall(tab5d.tmp, 5)))
#tab5[1:3, -c(4, 8, 12)] <- as.integer(tab5[1:3, -c(4, 8, 12)])
kable(tab5,  booktabs = T, format = 'markdown') 


cat('\begin{tabular}{|c *{13}{|C{1cm}}|} \cline{1-13}
    \multicolumn{1}{c|}{} & \multicolumn{2}{c|}{\textbf{Model ISAp75 \newline (Overall Accuracy = 0.89)}} & \multicolumn{2}{C{2.436cm}|}{\textbf{Model ISAp50 \newline (Overall Accuracy = 0.86)}} & \multicolumn{2}{C{2.436cm}|}{\textbf{Model ISAp75 \newline (Overall Accuracy = 0.89)}} % rest of table
\end{tabular}')

colnames(x) <- sprintf("\\emph{%s}", colnames(x)) # highlight colnames
rownames(x) <- sprintf("\\emph{%s}", rownames(x)) # highlight rownames

print(xtable(tab5),
      only.contents = TRUE, 
      comment = FALSE,
      sanitize.colnames.function = identity, 
      sanitize.rownames.function = identity, 
      hline.after = 0:2,...)


```   
  
\begin{center}
{Table 6. The overall, user’s, and producer’s accuracies of ISA class in annual maps from Model ISAp25, ISAp50, and ISAp75, with the highest values in bold among each accuracy in each year.}
\end{center}
  
  
```{r eval=T, echo=F, message=F, warning=F, results='asis'}
## Table 6. Annual Validation of results -------------
## Stock results
 valid.length <- integer(13)
 tab6.B <- list()
 tab6.C <- list()
 tab6.D <- list()
# 
 tab6.B <- annual_confusion_matrix(valid.pt, stk.B, 25)
 tab6.C <- annual_confusion_matrix(valid.pt, stk.C, 50)
 tab6.D <- annual_confusion_matrix(valid.pt, stk.D, 75)


tab6 <- matrix(ncol = 16, nrow = 13)
rownames(tab6) <- 2001:2013
num.v <- table(valid.pt@data$Year)
O_25p <- c(); O_50p <- c(); O_75p <- c()
Uimp_25p <- c(); Uimp_50p <- c(); Uimp_75p <- c()
Uoth_25p <- c(); Uoth_50p <- c(); Uoth_75p <- c()
Pimp_25p <- c(); Pimp_50p <- c(); Pimp_75p <- c()
Poth_25p <- c(); Poth_50p <- c(); Poth_75p <- c()
for (i in 1: 13) {
  O_25p[i] <- zapsmall(tab6.B[[i]][4,4],2)
  O_50p[i] <- zapsmall(tab6.C[[i]][4,4],2)
  O_75p[i] <- zapsmall(tab6.D[[i]][4,4],2)
  Uimp_25p[i] <- zapsmall(tab6.B[[i]][1,4],2)
  Uimp_50p[i] <- zapsmall(tab6.C[[i]][1,4],2)
  Uimp_75p[i] <- zapsmall(tab6.D[[i]][1,4],2)
  Uoth_25p[i] <- zapsmall(tab6.B[[i]][2,4],2)
  Uoth_50p[i] <- zapsmall(tab6.C[[i]][2,4],2)
  Uoth_75p[i] <- zapsmall(tab6.D[[i]][2,4],2)
  Pimp_25p[i] <- zapsmall(tab6.B[[i]][4,1],2)
  Pimp_50p[i] <- zapsmall(tab6.C[[i]][4,1],2)
  Pimp_75p[i] <- zapsmall(tab6.D[[i]][4,1],2)
  Poth_25p[i] <- zapsmall(tab6.B[[i]][4,2],2)
  Poth_50p[i] <- zapsmall(tab6.C[[i]][4,2],2)
  Poth_75p[i] <- zapsmall(tab6.D[[i]][4,2],2)
}

tab6 <- cbind(num.v,O_25p,O_50p,O_75p,Uimp_25p,Uimp_50p,Uimp_75p,Pimp_25p,Pimp_50p,Pimp_75p)
colnames(tab6) <- c("Num.v","O_25p","O_50p","O_75p","Uimp_25p","Uimp_50p","Uimp_75p","Pimp_25p","Pimp_50p","Pimp_75p")


kable(tab6,  booktabs = T, format = 'markdown') 

```   
  
## 3.4. Estimation of Total ISA

```{r eval=T, echo=F, message=F, warning=F, results='asis'}
Area.A <- NA
Area.B <- NA
Area.C <- NA
Area.D <- NA

for(n in 1:13){
  ## Area estimation
  Area.A[n] <- sum(freq(stk.A[[n]])[,1]*freq(stk.A[[n]])[,2],na.rm = T)/100*231.4311*231.4311/1000000
  Area.B[n] <- as.integer(freq(stk.B[[n]])[1,2])*231.4311*231.4311/1000000
  Area.C[n] <- as.integer(freq(stk.C[[n]])[1,2])*231.4311*231.4311/1000000
  Area.D[n] <- as.integer(freq(stk.D[[n]])[1,2])*231.4311*231.4311/1000000
}

```


  The total area size of ISA was estimated for each year in the study area for the period 2001–2013. Figure 7 shows the results of the sub-pixel classification for Model *ISAsub* along with those of the per-pixel classification for Model *ISAp25*, *ISAp50*, and *ISAp75*. All of the estimations from Models *ISAsub*, *ISAp25*, *ISAp50*, and *ISAp75* indicate a gradual increasing trend of ISA. The ISAs determined from sub-pixel classification in Model *ISAsub* showed a gradual increase from `r as.integer(Area.A[1])`  km^2^ in 2001 to `r as.integer(Area.A[13])` km^2^ in 2013, while those from the per-pixel classification varies according to the threshold in Models *ISAp25*, *ISAp50*, and *ISAp75*. The largest ISAs was found in Model *ISAp25* (`r as.integer(Area.B[1])`  to `r as.integer(Area.B[1])`  km^2^), while, the smallest was found in Model *ISAp75* (`r as.integer(Area.D[1])`  to `r as.integer(Area.D[13])`  km^2^). The ISA from Model *ISAp25* was `r as.integer(mean(Area.B - Area.D))` km^2^ larger than that of Model *ISAp75* on average during the study period as a result of the different threshold. Rates of increase from Models *ISAsub*, *ISAp25*, *ISAp50*, and *ISAp75* were `r sprintf('%.1f', lm(Area.A~Year)$coefficient[2])`, `r sprintf('%.1f', lm(Area.B~Year)$coefficient[2])`, `r sprintf('%.1f',  lm(Area.C~Year)$coefficient[2])`, and `r sprintf('%.1f',  lm(Area.D~Year)$coefficient[2])` (km^2^/year), respectively.  
 
 
```{r eval=T, echo=F, message=F, warning=F, results='asis', fig.width=9, fig.height=6, fig.cap=fig$cap("", " Estimation of total ISA by sub-pixel classification (Model ISAsub) and per-pixel classification (Model ISAp25, ISAp50, and ISAp75) and their linear trends during the period 2001–2013.")} 
## Fig. 7  --------------------------------------------------------------------
##ggplot
dat <- as.data.frame(cbind(Area.A,Area.B,Area.C,Area.D,Year))
names(dat) <- c("ISAsub","ISAp25","ISAp50","ISAp75","Year")
dat2 <- melt(dat,id = "Year",measure = c("ISAsub","ISAp25","ISAp50","ISAp75"))
names(dat2)[2] <- "Category"
xbreaks <- c(2000,2004,2008,2012)
p <- ggplot(dat2,aes(x = Year,y = value, group = Category, shape = Category))
p <- p +  theme_bw()
p <- p + ylab("Area (sq. km)")
p <- p + scale_x_continuous(breaks = c(2001,2004,2008,2012))
p <- p + theme(axis.title.x = element_text(size = 20),axis.title.y = element_text(size = 22)) 
p <- p + theme(axis.text.x = element_text(size = 20),axis.text.y = element_text(size = 22)) 
p <- p + theme(legend.text = element_text(size = 18), legend.title = element_blank(),legend.key = element_blank()) 
p <- p + theme(legend.position = "bottom")
p <- p +  geom_smooth(method = "lm",se = F,colour = "black")
p <- p +  geom_point(size = 3,colour = "black")
p

```
  

# 4. Discussion
## 4.1. Sub-Pixel Classification for Annual Proportional ISA Mappings

```{r eval=T, echo=F, message=F, warning=F, results='asis'}
##import landsat scale data
 imp05 <- raster("./data/imp05_ernan_utm48n.tif")
 imp10 <- raster("./data/imp10_ernan_utm48n.tif")

# #table(imp05[])
# #6673417 * 0.015 * 0.015
# #1501.519
# 
# #table(imp10[])
# #7694792 * 0.015 * 0.015
# 1731.328

```

  Previous studies have not identified ISA extent and its distribution annually in this study area. This is partly because of the lack of availability of sufficient high-resolution image data due to high levels of cloud cover, which commonly prevents the observation of ISAs, especially in tropical regions [@Hansen2012]. This research sought to overcome this issue by classifying annual pattern of post-filtered EVI. Although MODIS has a coarse spatial resolution (231.7 meters in this case), annual land cover proportion was estimated at each location by adopting a sub-pixel classification. The Model *ISAsub* results show the spatial and temporal trends of ISA distribution (Figure 3). In 2001, its extent was concentrated around the urban core. Since then ISA has increased gradually at the pace of `r sprintf('%.1f', lm(Area.A~Year)$coefficient[2])` km^2^ per year (Figure 7). This is the first time that the anecdotal knowledge of the spatio-temporal trends associated with ISA expansion in the JMA has been confirmed.  
  
  Model *ISAsub* describes distributions of ISAs continuously and its extents correspond to those of Landsat-based ISA maps analyzed by Rustiadi *et al.* (2012) (Figure 8a,b)) [@Rustiadi2012]. Figure 8c showed change in ISAs from 2005 to 2010 by Model *ISAsub* and by Landsat-based classification. It indicates considerable developments of ISAs in surrounding areas of DKI Jakarta. Losses of ISAs are shown mainly in northern costal areas from results of Model *ISAsub*, while any losses are not found in Landsat-based ISA maps. Aquaculture ponds are widely seen in such areas and these losses may be caused by misclassification of ISAs due to the similarity of temporal EVI profile with water body.  
  
  Rustiadi *et al.* (2012) estimated `r as.integer( table(imp05[]) * 0.015 * 0.015 )` km^2^ and `r as.integer( table(imp10[]) * 0.015 * 0.015 )` km^2^ of total ISAs in this region in 2005 and 2010, respectively by Landsat-based land cover classification [@Rustiadi2012]. Our results inferred `r as.integer(Area.A[5])`  km^2^ and `r as.integer(Area.A[10])`  km^2^ of total ISAs in 2005 and 2010, respectively, from the sub-pixel Model *ISAsub* using MODIS images, being in good agreement with the previous study, while per-pixel models indicated larger disagreements to previous studies (Figure 7). The Model *ISAsub* showed reasonable results compared to per-pixel approaches, although some improvements for minimizing the error should be considered. Figure 5 shows predicted values tend to overestimate to some extent where the ISA proportion is low, while underestimation where the ISA proportion is high. As areas of relatively low ISA proportion are dominated surrounding the city core, such areas may overestimate the degree of ISAs. It is, however, actual ISA such as settlements and roads in rural areas in this region that are often seen surrounded by other land covers (e.g., agricultural land or tree covers). Such ISAs can be represented by the Model *ISAsub*, while not by other per-pixel models because per-pixel models neglect small ISAs according to their thresholds of ISA proportion. Thus, although there remain some errors of results causing over-/under-estimation of ISAs, sub-pixel approach can be emphasized as a useful way of estimating ISAs. Quantifying land cover changes using produced ISA maps relies on high accuracy to avoid error-to-error inferences [@Tewkesbury2015b]. Table 4 shows R-squared and %RMSE of each map are not high significantly and it would make difficult to focus on annual change in ISA pixel-by-pixel. Figure 7 shows abrupt decreases in 2001–2002, 2003–2005, 2006–2007, 2008–2009, and 2012–2013 under Model *ISAsub*. Such trends have been reported in previous studies [@Sexton2013k; @Clark2012c; @Clark2010e]. As ISA is rarely converted into non-ISA, this unexpected trend may come from modeling errors. Minimizing such errors is always a challenge. However, it is possible to conclude in this research that ISA has been gradually increasing during 2001–2013. Developing highly accurate maps is a challenge that needs to be addressed to support future land cover change analyses.
  
  

```{r eval=T, echo=F, message=F, warning=F, results='asis', fig.width=9, fig.height=6}
## Fig. 8  --------------------------------------------------------------------

# These commands below are for making each map
# Fig 8 was assembled by GIMPS software
# so here only codes for making maps are shown

####compared with finer scale image
# 
# 
# imp05.aggr <- aggregate(imp05, fact=c(res(stk.A)[1]/res(imp05)[1],res(stk.A)[2]/res(imp05)[2] ), fun=sum, na.rm=TRUE)
# res(imp05.aggr)
# imp05.aggr <- imp05.aggr /225 * 100
# 
# stkA05.resamp <- resample(stk.A[[5]], imp05.aggr, method= "bilinear" )
# dif05 <- stkA05.resamp - imp05.aggr
# #plot(dif05)
# #plot(imp05.resamp)
# 
# 
# imp10.aggr <- aggregate(imp10, fact=c(res(stk.A)[1]/res(imp05)[1],res(stk.A)[2]/res(imp05)[2] ), fun=sum, na.rm=TRUE)
# res(imp10.aggr)
# imp10.aggr <- imp10.aggr /225 * 100
# 
# stkA10.resamp <- resample(stk.A[[10]], imp10.aggr, method= "bilinear" )
# dif10 <- stkA10.resamp - imp10.aggr
# #plot(dif10)
# 
# par(mfrow=c(2,2))
# plot(imp05)
# plot(stk.A[[5]])
# plot(imp10)
# plot(stk.A[[10]])
# 
# 
# #png("Fig8.png", width = 9, height = 6, units = "in", res = 150)
# stkA0510 <- stack(stk.A[[5]], stk.A[[10]])
# proj.wgs84 <- "+proj=longlat +datum=WGS84 +no_defs"
# stkA0510.latlon <- projectRaster(from=stkA0510, crs=proj.wgs84)
# rm(stkA0510)
# 
# ## north arrow & scale bar
# l2 = list("SpatialPolygonsRescale", layout.north.arrow(), offset = c(107.2,-6.05), 
#           scale = 0.1, which = 2)
# l3 = list("SpatialPolygonsRescale", layout.scale.bar(), offset = c(107.04,-6.72), 
#           scale = 0.226, fill=c("black"), which = 2)
# l4 = list("sp.text", c(107.04,-6.75), "0", which=2)
# l5 = list("sp.text", c(107.24,-6.75), "25 km", which=2)
# 
# tiff("Fig8a.tiff", width = 9, height = 6, units = "in", res = 250)
# print(spplot(stkA0510.latlon,  par.strip.text=list(cex=1.5),
#                names.attr =c("2005", "2010"), 
#                scales=list(draw=T, cex=1.15),
#                col.regions = colorRampPalette(c("#FFFFFF","#CCE5FF","#00CCCC","#000099","#000000")),
#                colorkey=list(at=seq(0,100,10), labels=list(paste(seq(0,100,20), sep=""), cex=1.5), space="bottom"),
#                sp.layout=list(l2,l3,l4,l5))
#         + layer(sp.polygons(bnd.JMA_latlon, lwd=0.5)))
#   dev.off()
#   
# 
# imp05.wgs84 <- raster("/Users/tsutsumida-mc/Dropbox/Workplace/INDONESIA/Paper1/imp05_ernan_wgs84.tif")
# imp10.wgs84 <- raster("/Users/tsutsumida-mc/Dropbox/Workplace/INDONESIA/Paper1/imp10_ernan_wgs84.tif")
# imp0510.wgs84.stk <- stack(imp05.wgs84, imp10.wgs84)
#  
# tiff("Fig8b.tiff", width = 9, height = 6, units = "in", res = 250)
# print(spplot(imp0510.wgs84.stk,  par.strip.text=list(cex=1.5),
#              names.attr =c("2005", "2010"), 
#              scales=list(draw=T, cex=1.15),
#              maxpixels = 1e7,
#              col.regions = c("#FFFFFF","#000090"),
#              colorkey = list(at=c(1, 0.5, 0), labels = list(at=c(0.75, 0.25), labels=c("ISA", "Non-ISA"), cex=1.5), space="bottom"),
#              sp.layout=list(l2,l3,l4,l5))
#       + layer(sp.polygons(bnd.JMA_latlon, lwd=0.5)))
# dev.off()
# 
# 
# l2c = list("SpatialPolygonsRescale", layout.north.arrow(), offset = c(107.2,-6.05), 
#           scale = 0.1)
# l3c = list("SpatialPolygonsRescale", layout.scale.bar(), offset = c(107.04,-6.72), 
#           scale = 0.226, fill=c("black"))
# l4c = list("sp.text", c(107.04,-6.75), "0")
# l5c = list("sp.text", c(107.24,-6.75), "25 km")
# 
# 
# stkA0510.latlon.dif <- stkA0510.latlon[[2]] - stkA0510.latlon[[1]]
# tiff("Fig8c1.tiff", width = 8, height = 8, units = "in", res = 250)
# spplot(stkA0510.latlon.dif,  par.strip.text=list(cex=3),
#         col.regions = c( "#D73027", "#F46D43", "#FDAE61", "#FEE08B", "#FFFFFF", "#D9EF8B", "#A6D96A", "#66BD63", "#1A9850"),
#         #c("#B2182B", "#D6604D", "#F4A582", "#FFFFFF", "#FFFFFF", "#92C5DE", "#4393C3", "#2166AC"),
#         cuts = 25 ,
#         maxpixels = 1e7,
#         at = seq(-90,90,20),
#         scales=list(draw=T, cex=1.8),
#        colorkey=list(labels=list( cex=1.8)),
#         sp.layout=list(l2c,l3c,l4c,l5c))  + layer(sp.polygons(bnd.JMA_latlon, lwd=0.5))
# dev.off()
# 
# 
# test1 <-  imp05.wgs84 
# test1[is.na(test1)] <- 0
# test2 <-  imp10.wgs84
# test2[is.na(test2)] <- 0
# imp10.latlon.dif <- test2 - test1
# imp10.latlon.dif[imp10.latlon.dif == 0] <- NA
# 
# tiff("Fig8c2.tiff", width = 8, height = 8, units = "in", res = 250)
# spplot(imp10.latlon.dif,  par.strip.text=list(cex=2.5), 
#        col.regions =  c( "#FFFFFF",  "#1A9850"),
#       # col.regions =  c( "#F46D43","#FFFFFF",  "#1A9850"),
#        cuts = 3 ,
#        at = c(0,1, 0.5),
#        scales=list(draw=T, cex=1.5),
#        maxpixels = 1e7,
#        sp.layout=list(l2c, l3c, l4c, l5c),
#        colorkey = list(at=c(1, 0.5, 0), labels = list(at=c(0.75, 0.25), labels=c("Increase", "No change"), cex=1.5))
#        )  + layer(sp.polygons(bnd.JMA_latlon, lwd=0.5))
# dev.off()
# 
# 
# 
# 
# plot(test,  main = "(c) ISA changes from 2005 to 2010 (Model ISA)", 
#      col=c("#B2182B", "#D6604D", "#F4A582", "#FFFFFF", "#FFFFFF", "#92C5DE", "#4393C3", "#2166AC")
#      )
# plot(bnd.JMA_latlon, add=T)
# 
# plot(test21,  main = "(c) ISA changes from 2005 to 2010 (Landsat-based per-pixel maps)", 
#      col=c("#4393C3"),lab=""
#      
#      
# )
# plot(bnd.JMA_latlon, add=T)
# 
# 

```
  

```{r echo=FALSE,fig.width=9,fig.cap=fig$cap("", "ISA maps in 2005 and 2010 estimated from (a) Model ISAsub; and (b) Landsat-based classification (source from Rustiadi et al. (2012)); and (c) change in ISAs from 2005 to 2010.")}
knitr::include_graphics('./Fig8.tif', auto_pdf = TRUE)
```
  

##4.2. Classification of Annual Patterns of EVI Time Series  
  This research analyzed the annual patterns of post-filtered EVI time series under the assumption that such patterns would adequately describe ISA. The classification of temporally aggregated phenological data and several other input variables can make the models difficult to interpret. We recognize that the annual patterns of EVI may be influenced by the local impacts of external factors and anomalies such as extreme weather events, haze, floods and El Nino and such impacts may change annual patterns of EVI. As a result, these factors may have impacts on the results and thereby provide limitations to this research. For example, phenological indices were extracted from annual patterns of EVI which may lack meaningful information for the classification and accuracy measures of a model incorporating four phenological indices (Table 3). However, as the reliability of the variables is indicated in Figure 4, variables during DOY 96–272 highly contribute to the model and this period corresponds to dry season (approximately from April to October, while the rainy season from November to March) in this region. Considering such climate condition by using all 23 variables would improve the result. Thus, this approach of classifying annual patterns of EVI time series data (in this case 23 variables) is simple, tractable and understandable in the context of land cover dynamics.  

## 4.3. Comparison with Per-Pixel Analyses 

  Per-pixel classifications result in different area estimations because of the different way that they “define” ISA: Model *ISAp25* uses an threshold of 25% of ISA proportion in the reference pixel and overestimates the ISA, and Models *ISAp50* and *ISAp75*, using thresholds of 50% and 75% of ISA in the reference pixel, respectively, underestimate the cover, when compared to the sub-pixel classification of Model *ISAsub* (Figure 7). This variation suggests that it is important to consider this threshold problem when applying per-pixel approaches to monitor land cover dynamics, but there is no particular way to overcome this issue.  

  When the per-pixel classification results are considered, reasonably high overall accuracies for the three models were found (Table 5). While overall accuracies increased with the threshold of ISA (Model *ISAp25* < *ISAp50* < *ISAp75*), the user’s and producer’s accuracies of ISA class show the opposite trend: Model *ISAp25* > *ISAp50* > *ISAp75*. This indicates the contribution that Other makes to the overall accuracies. These tendencies may be due to the nature of the random sampling procedures which produce high accuracies with widely distributed classes in the study area. Accuracy measures of user, producer, and overall were not shown to have a significant statistical relationship with the number of reference data points, with total area size of estimation, or with their intra-year variations. This implies that changes of accuracy are not associated with temporal changes and thus the analytical focus should be on the assessment of each thematic map. As this research aimed to produce annual ISA maps, the outputs of model *ISAp25* should be selected as the best among three per-pixel models in terms of high user’s and producer’s accuracy of ISA class. However, it is inevitable that estimated ISA pixels contain anticipated other land covers (75% at maximum) and the observation of ISA from per-pixel analyses might not be straightforward. Although per-pixel analyses are commonly employed due to their simplicity, and the ease with which they can be extended to a multi-class analysis, per-pixel analyses fail to take into account of the effects of mixed land cover [@Lu2011] and such effects increase when using coarse spatial resolution data.

## 4.4. Reference Data

  The classification results and their accuracy assessments depend on the reference data. In this instance, ground-based reference data collection by field survey is not feasible because of the practical difficulty of investigating large amounts of randomly sampled areas at different time steps [@Foody2002g]. Annual land cover can be recorded using historical VHR images such as Quickbird in GE [@Clark2010e], although lower volumes of VHR images were found in unpopulated areas and remote areas as well as sufficient historical VHR data were not available in GE for some years (e.g., data were relatively sparse in 2001, 2002, 2007, and 2008). Several recent studies have reported the geo-referencing errors of VHR images in GE to be in the range of 1.8–5.0 m RMSE [@Farah2014; @Mohammed2013; @Paredes-Hernandez2013]. While the geo-referencing accuracy should be taken into account for all VHR images, this is impractical and any errors would not affect our results severely because the coarse (231.7 m) resolution data was used.  
  
  Although GE is a useful historical VHR database for building reference data, a potential limitation still remains in the way that the class proportions were allocated in each location as this was by human interpretation. It is inevitable because users are not permitted to extract or to digitize VHR images in GE [@Google]. In order to demonstrate a novel method in this research, sub-pixel land cover proportions in the reference data were determined using intervals of 5%, manually interpreted from VHR images in GE. Finer proportions may be preferable (e.g., at 1% intervals) for machine learning approaches to sub-pixel mapping using reference data classified from higher resolution image data. While the use of better reference data would support a stronger understanding of ISAs and more reliable ISA information, no reference data are perfect matches with the information that they seek to calibrate (model) and validate and accordingly, other researchers have used aggregated reference data e.g., at 5% [@Kobayashi2013] or 10% intervals [@Colditz2015] for sub-pixel mappings.  
  
  Reference data can never perfectly match the epistemology and ontology of the predicted or modeled data. The implications are that remote sensing analyses never use perfect reference data to train or validate remote sensing products [@Foody2010a; @Comber2005]. The end result is that such analyses have to assume that the reference and classified image data have semantic meanings that match, and seek to minimize the mismatches. The manual interpretation of historical GE imagery in this work has sought to overcome these semantic differences and to accommodate the fact that availability of historical VHR images in GE varied spatially and temporally.  
  
  In summary, despite the potential benefits of building reference data from visual allocation of land cover proportion from VHR images in GE over space and time, there are some inevitable limitations of spatially and temporally unbalanced availability of VHR images, and misallocation by human interpretation. The results of this research would be further improved when those limitations are overcome.
  
## 4.5. Future Work

  Future work will be in a number of areas based on the results of this research. First, recent developments in accuracy assessments have yet to be applied to temporal analysis of land cover change. R-squared and %RMSE are convenient indices representing the goodness of regression models, but they indicate only global measures of accuracy in contrast to spatially explicit accuracy assessment techniques (e.g., [@Tsutsumida2015; @Comber2012b; @Foody2005b; @Comber2013d]). Future work will extend such approaches into spatio-temporal accuracy assessments. Second, stratified sampling scheme would be utilized in a spatio-temporal model, while our pre-analysis did not show a better result using this scheme (R-squared is 0.53). A larger number of reference data would be required for its sufficient implementation because the stratification should be considered in terms of both ISA proportion and obtained years. Our pre-analysis employed by stratified sampling may result in failure due to the lack of sufficient numbers of reference data. Evaluation of a spatio-temporal model using random and stratified sampling would be helpful for further improvement of ISA mapping. Thirdly, annual ISA maps of finer spatial resolution by a spatio-temporal sub-pixel classification model using such as multi-temporal Landsat images are expected. Producing annual proportional ISA mappings at a high spatial resolution is still a challenge. Sexton *et al.* (2013) inferred annual proportional ISAs in an east coast region of US from 1984 to 2010 using planimetric map as a referenced data [@Sexton2013k]. They applied individual models for each year, and the correlation coefficient was 0.64 (R-squared was 0.41). Although their approach seems applicable to other regions, it is still uncertain whether it is a feasible way in our study area, because of higher cloud covers in images compared to US [@Hansen2012], and unavailability of detailed referenced map. Moreover, the accuracy of the model was less tolerable than that of our model. It is expected to overcome these difficulties. Lastly, this research considered ISA because it is a fundamental component of urban land cover in this region. However, other vegetated land covers such as trees, home gardens, and parks are also important urban components, especially in the context of sustainable urban developments and their identification and analysis would support wider spatial planning initiatives: in the JMA urban green space development and consideration of local environmental issues have been prominent [@Kirmanto2012]. A detailed understanding of urban land cover dynamics would support such initiatives.  

#5. Conclusions
 This research produced annual maps showing the proportional impervious surface areas. A sub-pixel, proportional classification was successfully applied to annual patterns of MODIS EVI data using a RF regression that was trained on proportionally sampled reference data over space and time. The sub-pixel classification approach was found to be a more robust method compared to per-pixel classification because of the variability in the mapped outputs associated with the application of different thresholds of ISA proportion in the training data. This approach demonstrates the utility of analyzing proportional land cover mappings over space and time under conditions of rapid urban expansion. Although the spatial resolution of MODIS is coarse compared to higher resolution remotely sensed data (Landsat or SPOT), the proposed approach of estimating multi-temporal proportional ISA by sub-pixel classification provides an effective way to manage the mixed pixel problem and to provide reliable measurements of ISA. This approach is generic and can be applied in other regions and for other types of land covers.

#Acknowledgments
This research is funded by JSPS program “International Network-hub for Future Earth: Research for Global Sustainability”. This work was supported by JSPS KAKENHI Grant Number 15K21086. The authors appreciate four anonymous reviewers for their useful comments and suggestions.

#Author Contributions
Narumasa Tsutsumida and Alexis Comber wrote the R code to analyze the data and wrote the first draft. Kirsten Barrett supported building the research design and wrote the first draft. Izuru Saizen and Ernan Rustiadi contributed to interpreting the results.

#Conflicts of Interest
The authors declare no conflict of interest.



#References
